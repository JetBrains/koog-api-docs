<!doctype html>
<html class="no-js">
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1" charset="UTF-8">
    <title>prompt-executor-ollama-client</title>
<link href="../../../../images/logo-icon.svg" rel="icon" type="image/svg">    <script>var pathToRoot = "../../../../";</script>
    <script>document.documentElement.classList.replace("no-js","js");</script>
    <script>const storage = localStorage.getItem("dokka-dark-mode")
    if (storage == null) {
        const osDarkSchemePreferred = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches
        if (osDarkSchemePreferred === true) {
            document.getElementsByTagName("html")[0].classList.add("theme-dark")
        }
    } else {
        const savedDarkMode = JSON.parse(storage)
        if(savedDarkMode === true) {
            document.getElementsByTagName("html")[0].classList.add("theme-dark")
        }
    }
    </script>
<script type="text/javascript" src="https://unpkg.com/kotlin-playground@1/dist/playground.min.js" async></script>
<script type="text/javascript" src="../../../../scripts/sourceset_dependencies.js" async></script>
<link href="../../../../styles/style.css" rel="Stylesheet">
<link href="../../../../styles/main.css" rel="Stylesheet">
<link href="../../../../styles/prism.css" rel="Stylesheet">
<link href="../../../../styles/logo-styles.css" rel="Stylesheet">
<link href="../../../../styles/font-jb-sans-auto.css" rel="Stylesheet">
<link href="../../../../ui-kit/ui-kit.min.css" rel="Stylesheet">
<script type="text/javascript" src="../../../../scripts/clipboard.js" async></script>
<script type="text/javascript" src="../../../../scripts/navigation-loader.js" async></script>
<script type="text/javascript" src="../../../../scripts/platform-content-handler.js" async></script>
<script type="text/javascript" src="../../../../scripts/main.js" defer></script>
<script type="text/javascript" src="../../../../scripts/prism.js" async></script>
<script type="text/javascript" src="../../../../ui-kit/ui-kit.min.js" defer></script>
<script type="text/javascript" src="../../../../scripts/symbol-parameters-wrapper_deferred.js" defer></script></head>
<body>
    <div class="root">
    <nav class="navigation theme-dark" id="navigation-wrapper">
<a class="library-name--link" href="../../../../index.html">
                    koog-agents
            </a>        <button class="navigation-controls--btn navigation-controls--btn_toc ui-kit_mobile-only" id="toc-toggle" type="button">Toggle table of contents
        </button>
        <div class="navigation-controls--break ui-kit_mobile-only"></div>
        <div class="library-version" id="library-version">0.3.0
        </div>
        <div class="navigation-controls">
        <div class="filter-section filter-section_loading" id="filter-section">
                <button class="platform-tag platform-selector common-like" data-active="" data-filter=":prompt:prompt-executor:prompt-executor-clients:prompt-executor-ollama-client/commonMain">common</button>
            <div class="dropdown filter-section--dropdown" data-role="dropdown" id="filter-section-dropdown">
                <button class="button button_dropdown filter-section--dropdown-toggle" role="combobox" data-role="dropdown-toggle" aria-controls="platform-tags-listbox" aria-haspopup="listbox" aria-expanded="false" aria-label="Toggle source sets"></button>
                <ul role="listbox" id="platform-tags-listbox" class="dropdown--list" data-role="dropdown-listbox">
                    <div class="dropdown--header"><span>Platform filter</span>
                        <button class="button" data-role="dropdown-toggle" aria-label="Close platform filter">
                            <i class="ui-kit-icon ui-kit-icon_cross"></i>
                        </button>
                    </div>
                        <li role="option" class="dropdown--option platform-selector-option common-like" tabindex="0">
                            <label class="checkbox">
                                <input type="checkbox" class="checkbox--input" id=":prompt:prompt-executor:prompt-executor-clients:prompt-executor-ollama-client/commonMain" data-filter=":prompt:prompt-executor:prompt-executor-clients:prompt-executor-ollama-client/commonMain">
                                <span class="checkbox--icon"></span>
                                common
                            </label>
                        </li>
                </ul>
                <div class="dropdown--overlay"></div>
            </div>
        </div>
            <button class="navigation-controls--btn navigation-controls--btn_theme" id="theme-toggle-button" type="button">Switch theme
            </button>
            <div class="navigation-controls--btn navigation-controls--btn_search" id="searchBar" role="button">Search in
                API
            </div>
        </div>
    </nav>
        <div id="container">
            <div class="sidebar" id="leftColumn">
                <div class="dropdown theme-dark_mobile" data-role="dropdown" id="toc-dropdown">
                    <ul role="listbox" id="toc-listbox" class="dropdown--list dropdown--list_toc-list" data-role="dropdown-listbox">
                        <div class="dropdown--header">
                            <span>
                                    koog-agents
                            </span>
                            <button class="button" data-role="dropdown-toggle" aria-label="Close table of contents">
                                <i class="ui-kit-icon ui-kit-icon_cross"></i>
                            </button>
                        </div>
                        <div class="sidebar--inner" id="sideMenu"></div>
                    </ul>
                    <div class="dropdown--overlay"></div>
                </div>
            </div>
            <div id="main">
<div class="main-content" id="content" pageids="prompt-executor-ollama-client::////PointingToDeclaration//-848347435">
  <div class="breadcrumbs"></div>
  <div class="cover ">
    <h1 class="cover"><span><span>prompt-executor-ollama-client</span></span></h1>
    <div class="platform-hinted UnderCoverText" data-platform-hinted="data-platform-hinted"><div class="content sourceset-dependent-content" data-active="" data-togglable=":prompt:prompt-executor:prompt-executor-clients:prompt-executor-ollama-client/commonMain"><p class="paragraph">A client implementation for executing prompts using local Ollama models with limited multimodal support.</p><h3 class="">Overview</h3><p class="paragraph">This module provides a client implementation for the Ollama API, allowing you to execute prompts using locally hosted models. Ollama enables running large language models locally on your machine. The client currently supports text and basic image processing capabilities.</p><h3 class="">Supported Models</h3><h4 class="">Predefined Models (Groq)</h4><table><thead><tr><th>Model</th><th>Speed</th><th>Input Support</th><th>Output Support</th><th>Requirements</th></tr></thead><tbody><tr><td>llama3-groq-tool-use:8b</td><td>Fast</td><td>Text, Tools</td><td>Text, Tools</td><td>8GB+ RAM</td></tr><tr><td>llama3-groq-tool-use:70b</td><td>Medium</td><td>Text, Tools</td><td>Text, Tools</td><td>32GB+ RAM</td></tr></tbody></table><h4 class="">Predefined Models (Meta)</h4><table><thead><tr><th>Model</th><th>Speed</th><th>Input Support</th><th>Output Support</th><th>Requirements</th></tr></thead><tbody><tr><td>llama3.2:3b</td><td>Very Fast</td><td>Text, Tools</td><td>Text, Tools</td><td>4GB+ RAM</td></tr><tr><td>llama3.2</td><td>Fast</td><td>Text, Tools</td><td>Text, Tools</td><td>8GB+ RAM</td></tr><tr><td>llama4:latest</td><td>Medium</td><td>Text, Tools</td><td>Text, Tools</td><td>16GB+ RAM</td></tr></tbody></table><h4 class="">Predefined Models (Alibaba)</h4><table><thead><tr><th>Model</th><th>Speed</th><th>Input Support</th><th>Output Support</th><th>Requirements</th></tr></thead><tbody><tr><td>qwen2.5:0.5b</td><td>Very Fast</td><td>Text, Tools</td><td>Text, Tools</td><td>2GB+ RAM</td></tr><tr><td>qwen3:0.6b</td><td>Very Fast</td><td>Text, Tools</td><td>Text, Tools</td><td>2GB+ RAM</td></tr><tr><td>qwq</td><td>Fast</td><td>Text, Tools</td><td>Text, Tools</td><td>8GB+ RAM</td></tr><tr><td>qwen2.5-coder:32b</td><td>Medium</td><td>Text, Tools</td><td>Text, Tools</td><td>32GB+ RAM</td></tr></tbody></table><h4 class="">Dynamic Models</h4><p class="paragraph">Any model available in your local Ollama installation can be used by creating a dynamic model.</p><h3 class="">Media Content Support</h3><table><thead><tr><th>Content Type</th><th>Supported Formats</th><th>Max Size</th><th>Notes</th></tr></thead><tbody><tr><td>Images</td><td>❌ Not implemented</td><td>-</td><td>API supports it but client doesn't</td></tr><tr><td>Audio</td><td>❌ Not supported</td><td>-</td><td>-</td></tr><tr><td>Video</td><td>❌ Not supported</td><td>-</td><td>-</td></tr><tr><td>Documents</td><td>❌ Not supported</td><td>-</td><td>Use text extraction</td></tr></tbody></table><p class="paragraph"><strong>Important:</strong> While the Ollama API supports images via the <code class="lang-kotlin">images</code> field, this client implementation does not currently process <code class="lang-kotlin">MediaContent.Image</code>. Only text content is supported.</p><h3 class="">Using in your project</h3><p class="paragraph">Add the dependency to your project:</p><div class="sample-container"><pre><code class="block lang-kotlin" theme="idea">dependencies {<br>    implementation("ai.koog.prompt:prompt-executor-ollama-client:$version")<br>}</code></pre><span class="top-right-position"><span class="copy-icon"></span><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div></span></div><p class="paragraph">Configure the client with your Ollama server:</p><div class="sample-container"><pre><code class="block lang-kotlin" theme="idea">val ollamaClient = OllamaLLMClient(<br>    baseUrl = "http://localhost:11434", // Default Ollama server<br>)</code></pre><span class="top-right-position"><span class="copy-icon"></span><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div></span></div><h3 class="">Example of usage</h3><div class="sample-container"><pre><code class="block lang-kotlin" theme="idea">suspend fun main() {<br>    val client = OllamaLLMClient(<br>        baseUrl = "http://localhost:11434",<br>    )<br><br>    // Text-only example<br>    val response = client.execute(<br>        prompt = prompt {<br>            system("You are helpful assistant")<br>            user("What time is it now?")<br>        },<br>        model = OllamaModels.Meta.LLAMA_3_2_3B<br>    )<br><br>    println(response)<br>}</code></pre><span class="top-right-position"><span class="copy-icon"></span><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div></span></div><h3 class="">Usage Examples</h3><div class="sample-container"><pre><code class="block lang-kotlin" theme="idea">// Tool usage example<br>val toolResponse = client.execute(<br>    prompt = prompt {<br>        user("What's the weather like?")<br>    },<br>    model = OllamaModels.Meta.LLAMA_3_2,<br>    tools = listOf(weatherTool)<br>)<br><br>// Code generation<br>val codeResponse = client.execute(<br>    prompt = prompt {<br>        user("Write a Python function to calculate fibonacci numbers")<br>    },<br>    model = OllamaModels.Alibaba.QWEN_CODER_2_5_32B<br>)<br><br>// Dynamic model usage<br>val dynamicModel = client.createDynamicModel("codellama:13b")<br>val dynamicResponse = client.execute(<br>    prompt = prompt {<br>        user("Explain recursion")<br>    },<br>    model = dynamicModel<br>)<br><br>// Embedding example<br>val embeddingModel = client.createDynamicModel("nomic-embed-text")<br>val embedding = client.embed(<br>    text = "This is sample text for embedding",<br>    model = embeddingModel<br>)</code></pre><span class="top-right-position"><span class="copy-icon"></span><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div></span></div><h3 class="">Setup Instructions</h3><ol><li><p class="paragraph">Install Ollama: https://ollama.ai/</p></li><li><p class="paragraph">Pull a model: <code class="lang-kotlin">ollama pull llama3.1:8b</code></p></li><li><p class="paragraph">Start Ollama server: <code class="lang-kotlin">ollama serve</code></p></li><li><p class="paragraph">Use the client to connect to your local instance</p></li></ol></div></div>
  </div>
  <h2 class="">Packages</h2>
  <div class="table"><a data-name="-1385052104%2FPackages%2F-848347435" anchor-label="ai.koog.prompt.executor.ollama.client" id="-1385052104%2FPackages%2F-848347435" data-filterable-set=":prompt:prompt-executor:prompt-executor-clients:prompt-executor-ollama-client/commonMain"></a>
    <div class="table-row" data-filterable-current=":prompt:prompt-executor:prompt-executor-clients:prompt-executor-ollama-client/commonMain" data-filterable-set=":prompt:prompt-executor:prompt-executor-clients:prompt-executor-ollama-client/commonMain">
      <div>
        <div class="main-subrow ">
          <div class=""><span class="inline-flex">
              <div><a href="ai.koog.prompt.executor.ollama.client/index.html">ai.koog.prompt.executor.ollama.client</a></div>
<span class="anchor-wrapper"><span class="anchor-icon" pointing-to="-1385052104%2FPackages%2F-848347435"></span>
                <div class="copy-popup-wrapper "><span class="copy-popup-icon"></span><span>Link copied to clipboard</span></div>
              </span></span></div>
          <div class="pull-right">
            <div class="platform-tags no-gutters">
              <div class="platform-tag common-like">common</div>
            </div>
          </div>
        </div>
        <div></div>
      </div>
    </div>
<a data-name="-1350270968%2FPackages%2F-848347435" anchor-label="ai.koog.prompt.executor.ollama.tools.json" id="-1350270968%2FPackages%2F-848347435" data-filterable-set=":prompt:prompt-executor:prompt-executor-clients:prompt-executor-ollama-client/commonMain"></a>
    <div class="table-row" data-filterable-current=":prompt:prompt-executor:prompt-executor-clients:prompt-executor-ollama-client/commonMain" data-filterable-set=":prompt:prompt-executor:prompt-executor-clients:prompt-executor-ollama-client/commonMain">
      <div>
        <div class="main-subrow ">
          <div class=""><span class="inline-flex">
              <div><a href="ai.koog.prompt.executor.ollama.tools.json/index.html">ai.koog.prompt.executor.ollama.tools.json</a></div>
<span class="anchor-wrapper"><span class="anchor-icon" pointing-to="-1350270968%2FPackages%2F-848347435"></span>
                <div class="copy-popup-wrapper "><span class="copy-popup-icon"></span><span>Link copied to clipboard</span></div>
              </span></span></div>
          <div class="pull-right">
            <div class="platform-tags no-gutters">
              <div class="platform-tag common-like">common</div>
            </div>
          </div>
        </div>
        <div></div>
      </div>
    </div>
  </div>
</div>
    <div class="footer">
        <a href="#content" id="go-to-top-link" class="footer--button footer--button_go-to-top"></a>
        <span>Copyright © 2000-2025 JetBrains s.r.o.</span>
        <span class="pull-right">
            <span>Generated by </span>
            <a class="footer--link footer--link_external" href="https://github.com/Kotlin/dokka">
                <span>dokka</span>
            </a>
        </span>
    </div>
            </div>
        </div>
    </div>
</body>
</html>
