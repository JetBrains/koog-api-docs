<!doctype html>
<html class="no-js" lang="en">
<head>
    <meta name="viewport" content="width=device-width, initial-scale=1" charset="UTF-8">
    <title>koog-ktor</title>
<link href="../images/logo-icon.svg" rel="icon" type="image/svg"><script>var pathToRoot = "../";</script>
    <script>document.documentElement.classList.replace("no-js", "js");</script>
    <script>const storage = localStorage.getItem("dokka-dark-mode")
      if (storage == null) {
        const osDarkSchemePreferred = window.matchMedia && window.matchMedia('(prefers-color-scheme: dark)').matches
        if (osDarkSchemePreferred === true) {
          document.getElementsByTagName("html")[0].classList.add("theme-dark")
        }
      } else {
        const savedDarkMode = JSON.parse(storage)
        if (savedDarkMode === true) {
          document.getElementsByTagName("html")[0].classList.add("theme-dark")
        }
      }
    </script>
<script type="text/javascript" src="https://unpkg.com/kotlin-playground@1/dist/playground.min.js" async></script>
<script type="text/javascript" src="../scripts/sourceset_dependencies.js" async></script>
<link href="../styles/style.css" rel="Stylesheet">
<link href="../styles/main.css" rel="Stylesheet">
<link href="../styles/prism.css" rel="Stylesheet">
<link href="../styles/logo-styles.css" rel="Stylesheet">
<link href="../ui-kit/ui-kit.min.css" rel="Stylesheet">
<script type="text/javascript" src="../scripts/safe-local-storage_blocking.js"></script>
<script type="text/javascript" src="../scripts/navigation-loader.js" async></script>
<script type="text/javascript" src="../scripts/platform-content-handler.js" async></script>
<script type="text/javascript" src="../scripts/main.js" defer></script>
<script type="text/javascript" src="../scripts/prism.js" async></script>
<script type="text/javascript" src="../ui-kit/ui-kit.min.js" defer></script></head>
<body>
<div class="root">
    <header class="navigation theme-dark" id="navigation-wrapper" role="banner">
<a class="library-name--link" href="../index.html" tabindex="1">
                    koog
            </a>        <button class="navigation-controls--btn navigation-controls--btn_toc ui-kit_mobile-only" id="toc-toggle" type="button">Toggle table of contents
        </button>
        <div class="navigation-controls--break ui-kit_mobile-only"></div>
        <div class="library-version" id="library-version">0.6.3-SNAPSHOT
        </div>
        <div class="navigation-controls">
        <ul class="filter-section filter-section_loading" id="filter-section" aria-label="Target filter">
                <button class="platform-tag platform-selector common-like" data-active="" aria-pressed="true" data-filter=":koog-ktor/commonMain">common</button>
                <button class="platform-tag platform-selector jvm-like" data-active="" aria-pressed="true" data-filter=":koog-ktor/jvmMain">jvm</button>
            <div class="dropdown filter-section--dropdown" data-role="dropdown" id="filter-section-dropdown">
                <button class="button button_dropdown filter-section--dropdown-toggle" role="combobox" data-role="dropdown-toggle" aria-controls="platform-tags-listbox" aria-haspopup="listbox" aria-expanded="false" aria-label="Toggle source sets"></button>
                <ul role="listbox" id="platform-tags-listbox" class="dropdown--list" data-role="dropdown-listbox" aria-label="Target filter">
                    <div class="dropdown--header"><span>Target filter</span>
                        <button class="button" data-role="dropdown-toggle" aria-label="Close target filter">
                            <i class="ui-kit-icon ui-kit-icon_cross"></i>
                        </button>
                    </div>
                        <li role="option" class="dropdown--option platform-selector-option common-like" tabindex="0">
                            <label class="checkbox">
                                <input type="checkbox" class="checkbox--input" id=":koog-ktor/commonMain" data-filter=":koog-ktor/commonMain">
                                <span class="checkbox--icon"></span>
                                common
                            </label>
                        </li>
                        <li role="option" class="dropdown--option platform-selector-option jvm-like" tabindex="0">
                            <label class="checkbox">
                                <input type="checkbox" class="checkbox--input" id=":koog-ktor/jvmMain" data-filter=":koog-ktor/jvmMain">
                                <span class="checkbox--icon"></span>
                                jvm
                            </label>
                        </li>
                </ul>
                <div class="dropdown--overlay"></div>
            </div>
        </ul>
            <button class="navigation-controls--btn navigation-controls--btn_theme" id="theme-toggle-button" type="button">Switch theme
            </button>
            <div class="navigation-controls--btn navigation-controls--btn_search" id="searchBar" role="button">Search in
                API
            </div>
        </div>
    </header>
    <div id="container">
        <nav id="leftColumn" class="sidebar" data-item-type="SECTION" data-item-config="{&quot;defaultSize&quot;: 280, &quot;minSize&quot;: 200, &quot;maxSize&quot;: 400}">
            <a class="toc--skip-link" href="#main">Skip to content</a>
            <div class="dropdown theme-dark_mobile" data-role="dropdown" id="toc-dropdown">
                <ul role="listbox" id="toc-listbox" class="dropdown--list dropdown--list_toc-list" data-role="dropdown-listbox" aria-label="Table of contents">
                    <div class="dropdown--header">
                            <span>
                                    koog
                            </span>
                        <button class="button" data-role="dropdown-toggle" aria-label="Close table of contents">
                            <i class="ui-kit-icon ui-kit-icon_cross"></i>
                        </button>
                    </div>
                    <div class="sidebar--inner" id="sideMenu"></div>
                </ul>
                <div class="dropdown--overlay"></div>
            </div>
        </nav>
        <div id="resizer" class="resizer" data-item-type="BAR"></div>
        <div id="main" data-item-type="SECTION" role="main">
<div class="main-content" id="content" pageids="koog-ktor::////PointingToDeclaration//-402767446">
  <div class="breadcrumbs"></div>
  <div class="cover ">
    <h1 class="cover"><span><span>koog-ktor</span></span></h1>
    <div class="platform-hinted UnderCoverText with-platform-tabs" data-platform-hinted="data-platform-hinted">
      <div class="platform-bookmarks-row" data-toggle-list="data-toggle-list"><button class="platform-bookmark" data-filterable-current=":koog-ktor/commonMain" data-filterable-set=":koog-ktor/commonMain" data-active="" data-toggle=":koog-ktor/commonMain">common</button><button class="platform-bookmark" data-filterable-current=":koog-ktor/jvmMain" data-filterable-set=":koog-ktor/jvmMain" data-toggle=":koog-ktor/jvmMain">jvm</button></div>
<div class="content sourceset-dependent-content" data-active="" data-togglable=":koog-ktor/commonMain"><p class="paragraph">Ktor server integration for the Koog AI agents framework.</p><h2 class="">Overview</h2><p class="paragraph">The <code class="lang-kotlin">koog-ktor</code> module provides seamless integration between the Koog AI agents framework and Ktor server applications. It includes:</p><ul><li><p class="paragraph">A Ktor plugin for easy installation and configuration</p></li><li><p class="paragraph">Support for multiple LLM providers (OpenAI, Anthropic, Google, MistralAI, OpenRouter, DeepSeek, Ollama)</p></li><li><p class="paragraph">Agent configuration with tools, features, and prompt customization</p></li><li><p class="paragraph">Extension functions for routes to interact with LLMs and agents</p></li><li><p class="paragraph">JVM-specific support for Model Context Protocol (MCP) integration</p></li></ul><h2 class="">Using in your project</h2><p class="paragraph">Add the dependency to your <code class="lang-kotlin">build.gradle.kts</code>:</p><div class="sample-container"><pre><code class="block lang-kotlin" theme="idea">dependencies {<br>    implementation("ai.koog:koog-ktor:$koogVersion")<br>}</code></pre><span class="copy-tooltip"><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div><span class="copy-icon"></span></span></div><h2 class="">Basic Usage</h2><p class="paragraph">Provide one, or many apikey-s, and the Koog plugin will automatically connect to the provider when needed. For additional, or provider-specific settings, See #yamlconf-configuration below.</p><div class="sample-container"><pre><code class="block lang-yaml" theme="idea">koog:<br>  openai.apikey: "$OPENAI_API_KEY:your-openai-api-key"<br>  anthropic.apikey: "$ANTHROPIC_API_KEY:your-anthropic-api-key"<br>  google.apikey: "$GOOGLE_API_KEY:your-google-api-key"<br>  mistral.apikey: "$MISTRALAI_API_KEY:your-mistralai-api-key"<br>  openrouter.apikey: "$OPENROUTER_API_KEY:your-openrouter-api-key"<br>  deepseek.apikey: "$DEEPSEEK_API_KEY:your-deepseek-api-key"<br>  ollama.enabled: "$DEBUG:false"</code></pre><span class="copy-tooltip"><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div><span class="copy-icon"></span></span></div><h3 class="">Installing and configuring the plugin</h3><p class="paragraph">The Koog plugin can also be configured by code, and some complex configurations can only be done by code. See #programmatic-configuration below.</p><div class="sample-container"><pre><code class="block lang-kotlin" theme="idea">fun Application.module() {<br>    install(Koog) {<br>        llm {<br>            openAI(apiKey = "your-openai-api-key")<br>            anthropic(apiKey = "your-anthropic-api-key")<br>            ollama { baseUrl = "http://localhost:11434" }<br>            google(apiKey = "your-google-api-key")<br>            mistral(apiKey = "your-mistral-api-key")<br>            openRouter(apiKey = "your-openrouter-api-key")<br>            deepSeek(apiKey = "your-deepseek-api-key")<br>        }<br>    }<br><br>    routing {<br>        route("/ai") {<br>            post("/chat") {<br>                val userInput = call.receive&lt;String&gt;()<br>                val output = aiAgent(userInput)<br>                call.respond(HttpStatusCode.OK, output)<br>            }<br>        }<br>    }<br>}</code></pre><span class="copy-tooltip"><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div><span class="copy-icon"></span></span></div><h2 class="">Advanced Usage</h2><h3 class="">Content Moderation</h3><div class="sample-container"><pre><code class="block lang-kotlin" theme="idea">post("/moderated-chat") {<br>    val userInput = call.receive&lt;String&gt;()<br><br>    // Moderate content<br>    val isHarmful = llm().moderate(prompt("id") {<br>        user(userRequest)<br>    }, OpenAIModels.Moderation.Omni).isHarmful<br><br>    if (isHarmful) {<br>        call.respond(HttpStatusCode.BadRequest, "Harmful content detected")<br>        return@post<br>    }<br><br>    val output = aiAgent(userInput)<br>    call.respond(HttpStatusCode.OK, output)<br>}</code></pre><span class="copy-tooltip"><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div><span class="copy-icon"></span></span></div><h3 class="">Direct LLM Interaction</h3><div class="sample-container"><pre><code class="block lang-kotlin" theme="idea">post("/llm-chat") {<br>    val userInput = call.receive&lt;String&gt;()<br><br>    val response = llm().execute(prompt("id") {<br>        system(<br>            "You are a helpful assistant that can correct user answers. " +<br>                    "You will get a user's question and your task is to make it more clear for the further processing."<br>        )<br>        user(userRequest)<br>    }, OllamaModels.Meta.LLAMA_3_2)<br><br>    call.respond(HttpStatusCode.OK, response.content)<br>}</code></pre><span class="copy-tooltip"><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div><span class="copy-icon"></span></span></div><h3 class="">Custom Agent Strategies</h3><div class="sample-container"><pre><code class="block lang-kotlin" theme="idea">post("/custom-agent") {<br>    val userInput = call.receive&lt;String&gt;()<br><br>    val output = aiAgent(reActStrategy(), userInput)<br>    call.respond(HttpStatusCode.OK, output)<br>}</code></pre><span class="copy-tooltip"><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div><span class="copy-icon"></span></span></div><h2 class="">Configuration Options</h2><h3 class="">LLM Configuration</h3><h4 class="">Programmatic Configuration</h4><p class="paragraph">Configure multiple LLM providers with custom settings in code:</p><div class="sample-container"><pre><code class="block lang-kotlin" theme="idea">llm {<br>    openAI(apiKey = "your-openai-api-key") {<br>        baseUrl = "https://api.openai.com"<br>        timeouts {<br>            requestTimeoutMillis = 30000<br>            connectTimeoutMillis = 10000<br>            socketTimeoutMillis = 30000<br>        }<br>    }<br><br>    // Set fallback LLM<br>    fallback {<br>        provider = LLMProvider.Ollama<br>        model = OllamaModels.Meta.LLAMA_3_2<br>    }<br>}</code></pre><span class="copy-tooltip"><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div><span class="copy-icon"></span></span></div><h4 class="">YAML/CONF Configuration</h4><p class="paragraph">You can also configure LLM providers using YAML or CONF files. The plugin will automatically read the configuration from the application's configuration file:</p><div class="sample-container"><pre><code class="block lang-yaml" theme="idea"># application.yaml or application.conf<br>koog:<br>  openai:<br>    apikey: "your-openai-api-key"<br>    baseUrl: "https://api.openai.com"<br>    timeout:<br>      requestTimeoutMillis: 30000<br>      connectTimeoutMillis: 10000<br>      socketTimeoutMillis: 30000<br><br>  anthropic:<br>    apikey: "your-anthropic-api-key"<br>    baseUrl: "https://api.anthropic.com"<br>    timeout:<br>      requestTimeoutMillis: 30000<br><br>  google:<br>    apikey: "your-google-api-key"<br>    baseUrl: "https://generativelanguage.googleapis.com"<br><br>  mistral:<br>    apikey: "your-mistral-api-key"<br>    baseUrl: "https://api.mistral.ai"<br><br>  openrouter:<br>    apikey: "your-openrouter-api-key"<br>    baseUrl: "https://openrouter.ai"<br>    <br>  deepseek:<br>    apikey: "your-deepseek-api-key"<br>    baseUrl: "https://api.deepseek.com"<br><br>  ollama:<br>    baseUrl: "http://localhost:11434"<br>    timeout:<br>      requestTimeoutMillis: 60000</code></pre><span class="copy-tooltip"><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div><span class="copy-icon"></span></span></div><p class="paragraph">When using configuration files, you can still provide programmatic configuration that will override the settings from the file:</p><div class="sample-container"><pre><code class="block lang-kotlin" theme="idea">install(Koog) {<br>    // Optional: Override or add to configuration from YAML/CONF<br>    llm {<br>        // This will override the API key from the configuration file<br>        openAI(apiKey = System.getenv("OPENAI_API_KEY") ?: "override-from-code")<br>    }<br><br>    // Rest of your configuration...<br>}</code></pre><span class="copy-tooltip"><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div><span class="copy-icon"></span></span></div><h3 class="">Agent Configuration</h3><p class="paragraph">Configure agent behavior, tools, and features:</p><div class="sample-container"><pre><code class="block lang-kotlin" theme="idea">agent {<br>    // Set model<br>    model = OpenAIModels.GPT4.Turbo<br><br>    // Set max iterations<br>    maxAgentIterations = 10<br><br>    // Register tools<br>    registerTools {<br>        tool(::searchTool)<br>        tool(::calculatorTool)<br>    }<br><br>    // Configure prompt<br>    prompt {<br>        system("You are a helpful assistant specialized in...")<br>    }<br><br>    // Install features<br>    install(OpenTelemetry) {<br>        // Configure feature<br>    }<br>}</code></pre><span class="copy-tooltip"><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div><span class="copy-icon"></span></span></div><h3 class="">JVM-specific MCP Configuration</h3><p class="paragraph">Configure Model Context Protocol integration (JVM only):</p><div class="sample-container"><pre><code class="block lang-kotlin" theme="idea">agent {<br>    mcp {<br>        // Use Server-Sent Events<br>        sse("https://your-mcp-server.com/sse")<br><br>        // Or use process<br>        process(yourMcpProcess)<br><br>        // Or use existing client<br>        client(yourMcpClient)<br>    }<br>}</code></pre><span class="copy-tooltip"><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div><span class="copy-icon"></span></span></div></div><div class="content sourceset-dependent-content" data-togglable=":koog-ktor/jvmMain"><p class="paragraph">Ktor server integration for the Koog AI agents framework.</p><h2 class="">Overview</h2><p class="paragraph">The <code class="lang-kotlin">koog-ktor</code> module provides seamless integration between the Koog AI agents framework and Ktor server applications. It includes:</p><ul><li><p class="paragraph">A Ktor plugin for easy installation and configuration</p></li><li><p class="paragraph">Support for multiple LLM providers (OpenAI, Anthropic, Google, MistralAI, OpenRouter, DeepSeek, Ollama)</p></li><li><p class="paragraph">Agent configuration with tools, features, and prompt customization</p></li><li><p class="paragraph">Extension functions for routes to interact with LLMs and agents</p></li><li><p class="paragraph">JVM-specific support for Model Context Protocol (MCP) integration</p></li></ul><h2 class="">Using in your project</h2><p class="paragraph">Add the dependency to your <code class="lang-kotlin">build.gradle.kts</code>:</p><div class="sample-container"><pre><code class="block lang-kotlin" theme="idea">dependencies {<br>    implementation("ai.koog:koog-ktor:$koogVersion")<br>}</code></pre><span class="copy-tooltip"><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div><span class="copy-icon"></span></span></div><h2 class="">Basic Usage</h2><p class="paragraph">Provide one, or many apikey-s, and the Koog plugin will automatically connect to the provider when needed. For additional, or provider-specific settings, See #yamlconf-configuration below.</p><div class="sample-container"><pre><code class="block lang-yaml" theme="idea">koog:<br>  openai.apikey: "$OPENAI_API_KEY:your-openai-api-key"<br>  anthropic.apikey: "$ANTHROPIC_API_KEY:your-anthropic-api-key"<br>  google.apikey: "$GOOGLE_API_KEY:your-google-api-key"<br>  mistral.apikey: "$MISTRALAI_API_KEY:your-mistralai-api-key"<br>  openrouter.apikey: "$OPENROUTER_API_KEY:your-openrouter-api-key"<br>  deepseek.apikey: "$DEEPSEEK_API_KEY:your-deepseek-api-key"<br>  ollama.enabled: "$DEBUG:false"</code></pre><span class="copy-tooltip"><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div><span class="copy-icon"></span></span></div><h3 class="">Installing and configuring the plugin</h3><p class="paragraph">The Koog plugin can also be configured by code, and some complex configurations can only be done by code. See #programmatic-configuration below.</p><div class="sample-container"><pre><code class="block lang-kotlin" theme="idea">fun Application.module() {<br>    install(Koog) {<br>        llm {<br>            openAI(apiKey = "your-openai-api-key")<br>            anthropic(apiKey = "your-anthropic-api-key")<br>            ollama { baseUrl = "http://localhost:11434" }<br>            google(apiKey = "your-google-api-key")<br>            mistral(apiKey = "your-mistral-api-key")<br>            openRouter(apiKey = "your-openrouter-api-key")<br>            deepSeek(apiKey = "your-deepseek-api-key")<br>        }<br>    }<br><br>    routing {<br>        route("/ai") {<br>            post("/chat") {<br>                val userInput = call.receive&lt;String&gt;()<br>                val output = aiAgent(userInput)<br>                call.respond(HttpStatusCode.OK, output)<br>            }<br>        }<br>    }<br>}</code></pre><span class="copy-tooltip"><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div><span class="copy-icon"></span></span></div><h2 class="">Advanced Usage</h2><h3 class="">Content Moderation</h3><div class="sample-container"><pre><code class="block lang-kotlin" theme="idea">post("/moderated-chat") {<br>    val userInput = call.receive&lt;String&gt;()<br><br>    // Moderate content<br>    val isHarmful = llm().moderate(prompt("id") {<br>        user(userRequest)<br>    }, OpenAIModels.Moderation.Omni).isHarmful<br><br>    if (isHarmful) {<br>        call.respond(HttpStatusCode.BadRequest, "Harmful content detected")<br>        return@post<br>    }<br><br>    val output = aiAgent(userInput)<br>    call.respond(HttpStatusCode.OK, output)<br>}</code></pre><span class="copy-tooltip"><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div><span class="copy-icon"></span></span></div><h3 class="">Direct LLM Interaction</h3><div class="sample-container"><pre><code class="block lang-kotlin" theme="idea">post("/llm-chat") {<br>    val userInput = call.receive&lt;String&gt;()<br><br>    val response = llm().execute(prompt("id") {<br>        system(<br>            "You are a helpful assistant that can correct user answers. " +<br>                    "You will get a user's question and your task is to make it more clear for the further processing."<br>        )<br>        user(userRequest)<br>    }, OllamaModels.Meta.LLAMA_3_2)<br><br>    call.respond(HttpStatusCode.OK, response.content)<br>}</code></pre><span class="copy-tooltip"><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div><span class="copy-icon"></span></span></div><h3 class="">Custom Agent Strategies</h3><div class="sample-container"><pre><code class="block lang-kotlin" theme="idea">post("/custom-agent") {<br>    val userInput = call.receive&lt;String&gt;()<br><br>    val output = aiAgent(reActStrategy(), userInput)<br>    call.respond(HttpStatusCode.OK, output)<br>}</code></pre><span class="copy-tooltip"><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div><span class="copy-icon"></span></span></div><h2 class="">Configuration Options</h2><h3 class="">LLM Configuration</h3><h4 class="">Programmatic Configuration</h4><p class="paragraph">Configure multiple LLM providers with custom settings in code:</p><div class="sample-container"><pre><code class="block lang-kotlin" theme="idea">llm {<br>    openAI(apiKey = "your-openai-api-key") {<br>        baseUrl = "https://api.openai.com"<br>        timeouts {<br>            requestTimeoutMillis = 30000<br>            connectTimeoutMillis = 10000<br>            socketTimeoutMillis = 30000<br>        }<br>    }<br><br>    // Set fallback LLM<br>    fallback {<br>        provider = LLMProvider.Ollama<br>        model = OllamaModels.Meta.LLAMA_3_2<br>    }<br>}</code></pre><span class="copy-tooltip"><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div><span class="copy-icon"></span></span></div><h4 class="">YAML/CONF Configuration</h4><p class="paragraph">You can also configure LLM providers using YAML or CONF files. The plugin will automatically read the configuration from the application's configuration file:</p><div class="sample-container"><pre><code class="block lang-yaml" theme="idea"># application.yaml or application.conf<br>koog:<br>  openai:<br>    apikey: "your-openai-api-key"<br>    baseUrl: "https://api.openai.com"<br>    timeout:<br>      requestTimeoutMillis: 30000<br>      connectTimeoutMillis: 10000<br>      socketTimeoutMillis: 30000<br><br>  anthropic:<br>    apikey: "your-anthropic-api-key"<br>    baseUrl: "https://api.anthropic.com"<br>    timeout:<br>      requestTimeoutMillis: 30000<br><br>  google:<br>    apikey: "your-google-api-key"<br>    baseUrl: "https://generativelanguage.googleapis.com"<br><br>  mistral:<br>    apikey: "your-mistral-api-key"<br>    baseUrl: "https://api.mistral.ai"<br><br>  openrouter:<br>    apikey: "your-openrouter-api-key"<br>    baseUrl: "https://openrouter.ai"<br>    <br>  deepseek:<br>    apikey: "your-deepseek-api-key"<br>    baseUrl: "https://api.deepseek.com"<br><br>  ollama:<br>    baseUrl: "http://localhost:11434"<br>    timeout:<br>      requestTimeoutMillis: 60000</code></pre><span class="copy-tooltip"><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div><span class="copy-icon"></span></span></div><p class="paragraph">When using configuration files, you can still provide programmatic configuration that will override the settings from the file:</p><div class="sample-container"><pre><code class="block lang-kotlin" theme="idea">install(Koog) {<br>    // Optional: Override or add to configuration from YAML/CONF<br>    llm {<br>        // This will override the API key from the configuration file<br>        openAI(apiKey = System.getenv("OPENAI_API_KEY") ?: "override-from-code")<br>    }<br><br>    // Rest of your configuration...<br>}</code></pre><span class="copy-tooltip"><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div><span class="copy-icon"></span></span></div><h3 class="">Agent Configuration</h3><p class="paragraph">Configure agent behavior, tools, and features:</p><div class="sample-container"><pre><code class="block lang-kotlin" theme="idea">agent {<br>    // Set model<br>    model = OpenAIModels.GPT4.Turbo<br><br>    // Set max iterations<br>    maxAgentIterations = 10<br><br>    // Register tools<br>    registerTools {<br>        tool(::searchTool)<br>        tool(::calculatorTool)<br>    }<br><br>    // Configure prompt<br>    prompt {<br>        system("You are a helpful assistant specialized in...")<br>    }<br><br>    // Install features<br>    install(OpenTelemetry) {<br>        // Configure feature<br>    }<br>}</code></pre><span class="copy-tooltip"><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div><span class="copy-icon"></span></span></div><h3 class="">JVM-specific MCP Configuration</h3><p class="paragraph">Configure Model Context Protocol integration (JVM only):</p><div class="sample-container"><pre><code class="block lang-kotlin" theme="idea">agent {<br>    mcp {<br>        // Use Server-Sent Events<br>        sse("https://your-mcp-server.com/sse")<br><br>        // Or use process<br>        process(yourMcpProcess)<br><br>        // Or use existing client<br>        client(yourMcpClient)<br>    }<br>}</code></pre><span class="copy-tooltip"><div class="copy-popup-wrapper popup-to-left"><span class="copy-popup-icon"></span><span>Content copied to clipboard</span></div><span class="copy-icon"></span></span></div></div>    </div>
  </div>
  <h2 class="">Packages</h2>
  <div class="table"><a data-name="-393141734%2FPackages%2F-402767446" anchor-label="ai.koog.ktor" id="-393141734%2FPackages%2F-402767446" data-filterable-set=":koog-ktor/commonMain,:koog-ktor/jvmMain"></a>
    <div class="table-row table-row_platform-tagged" data-filterable-current=":koog-ktor/commonMain,:koog-ktor/jvmMain" data-filterable-set=":koog-ktor/commonMain,:koog-ktor/jvmMain">
      <div>
        <div class="main-subrow ">
          <div class=""><span class="inline-flex">
              <div><a href="ai.koog.ktor/index.html">ai.koog.ktor</a></div>
<span class="anchor-wrapper"><span class="anchor-icon" pointing-to="-393141734%2FPackages%2F-402767446"></span>
                <div class="copy-popup-wrapper "><span class="copy-popup-icon"></span><span>Link copied to clipboard</span></div>
              </span></span></div>
          <div class="pull-right platform-tags--wrapper">
            <div class="platform-tags no-gutters">
              <div class="platform-tag common-like">common</div>
              <div class="platform-tag jvm-like">jvm</div>
            </div>
          </div>
        </div>
        <div></div>
      </div>
    </div>
  </div>
</div>
    <div class="footer">
        <div class="footer--container">
            <a href="#content" id="go-to-top-link" class="footer--button footer--button_go-to-top"></a>
            <div class="footer--content">
                <div>
                    <span>Generated by </span>
                    <a class="footer--link footer--link_external" href="https://github.com/Kotlin/dokka">
                        Dokka
                    </a>
                    <div>Copyright Â© 2000-2025 JetBrains s.r.o.</div>
                </div>
            </div>
        </div>
    </div>
        </div>
    </div>
</div>
</body>
</html>